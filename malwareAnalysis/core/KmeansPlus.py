from sklearn.cluster import KMeans
import numpy as np
import pandas as pd
import warnings
from sklearn import metrics
from sklearn import preprocessing
import math

warnings.filterwarnings("ignore")

# 计算欧氏距离
def distEclud(x,y):
    return np.sqrt(np.sum((x-y)**2))

# 计算平均距离
def mdist(dataSet):
    m,n = np.shape(dataSet)

    # 距离之和
    Sum_Dist = 0.0
    num = 0
    for i in range(m):
        for j in range(m):
            if i == j:
                continue
            num += 1
            Sum_Dist += distEclud(dataSet[i,:],dataSet[j,:])
    
    Mdist = Sum_Dist / num
    return Mdist

# 求标准差
def sdist(dataSet,Mdist):
    m,n = np.shape(dataSet)
    Sum_Dist = 0.0
    num = 0
    for i in range(m):
        for j in range(m):
            if i ==j:
                continue
            Sum_Dist += ((Mdist-(distEclud(dataSet[i,:],dataSet[j,:])))**2)
            num += 1
    SDist = Sum_Dist / num
    SDist = math.sqrt(SDist)
    return SDist

# 数据对象点的密度函数值
def density(dataSet,SDist,i):
    m,n = np.shape(dataSet)
    alltemp = 0
    for j in range(m):
        if SDist < distEclud(dataSet[i,:],dataSet[j,:]):
            temp = 0
        else:
            temp = 1
        alltemp += temp
    return alltemp

# 计算平均密度
def mdensity(dataSet, SDist):
    m,n = np.shape(dataSet)
    MDensity = 0.0
    for i in range(m):
        temp = density(dataSet,SDist,i)
        MDensity += temp
    MDensity = MDensity / m
    return MDensity

# 计算密度标准差
def sdensity(dataSet,SDist,MDensity):
    m,n = np.shape(dataSet)
    #距离之和
    SDensity = 0.0

    for i in range(m):
        SDensity += ((MDensity - density(dataSet,SDist,i))**2 )

    SDensity = SDensity / m
    SDensity = math.sqrt(SDensity)
    return SDensity

# 确定最佳 k 值
def k_cluster(dataSet):
    origin_dataSet = dataSet

    m,n = np.shape(dataSet)

    k = 0
    #初始质心
    centroids = np.zeros((0,n), dtype = np.int)
    #样本的平均距离
    Mdist = 0.0
    #样本的标准差
    SDist = 0.0
    #样本的平均密度
    MDensity = 0.0
    #样本的密度标准差
    SDensity = 0.0
    len_M_density = 0
    #孤立点
    Guli_dataSet = np.zeros((0,n), dtype = np.int)
    #非孤立点
    Q_dataSet = np.zeros((0,n), dtype = np.int)
    #密度函数值
    D_density = np.zeros(0, dtype = np.int)
    #大于密度标准差的密度函数值
    M_density = np.zeros((0,1), dtype = np.int)
    #找出孤立点和非孤立点

    # 求样本的平均距离
    Mdist = mdist(dataSet)
    # 求样本的标准差
    SDist = sdist(dataSet,Mdist)
    # 样本的平均密度
    MDensity = mdensity(dataSet,SDist)
    # 样本的密码标准差
    SDensity = sdensity(dataSet,SDist,MDensity)

    #找出大于密度标准差的所有值,即孤立点

    # label
    label_list = []

    # 再原始位置上判断孤立点位置，，0为非孤立点，1为孤立点
    Q_dataSet_toOrigin = np.zeros(m, dtype = np.int)
    Q_dataSet_number = 0
    for i in range(m):
        if density(dataSet,SDist,i) < SDensity*0.4:
            Guli_dataSet = np.append(Guli_dataSet,[dataSet[i,:]],axis=0)
            origin_dataSet[i,0]=100
        else:
            Q_dataSet = np.append(Q_dataSet,[dataSet[i,:]],axis=0)
            label_list.append(i)
            Q_dataSet_toOrigin[Q_dataSet_number]= i
            Q_dataSet_number+=1
            #新的数据集

    mm,nn = np.shape(Q_dataSet)


    #Q集合，即非孤立点的密度函数值存入集合D，
    Mdist = mdist(Q_dataSet)

    SDist = sdist(Q_dataSet,Mdist)
    MDensity = mdensity(Q_dataSet,SDist)
    SDensity = sdensity(Q_dataSet,SDist,MDensity)

    for i in range(mm):
        temp = density(Q_dataSet,SDist,i)
        D_density = np.append(D_density,np.array(temp))

    #k值最大为10
    for abc in range(10):
        #将大于密度标准差的密度函数值放入集合M[密度值，位置]
        M_density = np.zeros((0,2), dtype = np.int)
        for i in range(mm):
            temp = D_density[i]
            if temp > 1.6*SDensity and temp >0:
                M_density = np.append(M_density,np.array([[temp,i]]),axis=0)
        len_M_density = len(M_density)
        if len_M_density == 0:
            break
        #找到M中密度函数最大值MAX在Q中对应的样本点Xi即为初始聚类中心。
        maxnum_1 = 0
        max_1 = 0
        for i in range(len_M_density):
            if M_density[i,0] > max_1:
                max_1 = M_density[i,0]
                maxnum_1 = M_density[i,1]
        #将以初始聚类中心为圆心，样本标准差为半径的圆内所有点的密度函数值赋为0
        for i in range(mm):
            distance_temp = distEclud(Q_dataSet[maxnum_1,:],Q_dataSet[i,:])
            if distance_temp <= SDist:
                D_density[i] = 0
            D_density[maxnum_1] = 0

        k += 1
        centroids = np.append(centroids,[Q_dataSet[maxnum_1,:]] ,axis=0)

    return label_list,k,centroids,Q_dataSet,origin_dataSet,Q_dataSet_toOrigin,Q_dataSet_number

def kmeansplus(dataSet):
    # 找到最佳k值，以及初始中心点
    label_list,k,myinit,Q_dataSet,origin_dataSet,Q_dataSet_toOrigin,Q_dataSet_number = k_cluster(dataSet)

    clf = KMeans(init=myinit, n_clusters=k, max_iter=3000)
    clf = clf.fit(Q_dataSet)
    result = clf.predict(Q_dataSet)

    # print("兰德系数：",metrics.adjusted_rand_score(y,result))
    # print("同质性",metrics.homogeneity_score(y, result))
    # print("ch",metrics.calinski_harabaz_score(Q_dataSet, result))
    return result